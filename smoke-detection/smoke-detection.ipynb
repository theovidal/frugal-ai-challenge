{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Smoke detection in images\n",
    "\n",
    "[Dataset](https://huggingface.co/datasets/pyronear/pyro-sdis)\n",
    "\n",
    "Goal: detect smoke in photographs of forests, mountains... using bounding boxes"
   ],
   "id": "f93eea1744abe734"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import libraries and select device",
   "id": "bb6e88b8c7f12f7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T07:09:25.174283Z",
     "start_time": "2025-02-03T07:09:21.111501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torchinfo import summary\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device {device}')\n",
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ],
   "id": "f16b1557b0e0b2be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/theovld/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Using device cuda\n",
      "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8eb107cb4d9d2ce9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset pipeline",
   "id": "dca4c259866bc400"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Transforming from Hugging Face to Ultralytics\n",
    "\n",
    "We save the images from the dataset in the current folder, with the Ultralytics YOLO format for the program to read it properly. The corresponding .yaml file is already writen."
   ],
   "id": "ec91939282422a9a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-03T06:22:12.623636Z",
     "start_time": "2025-02-03T06:22:07.206819Z"
    }
   },
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define paths\n",
    "REPO_ID = \"pyronear/pyro-sdis\"\n",
    "OUTPUT_DIR = \"datasets/pyro-sdis\"\n",
    "IMAGE_DIR = os.path.join(OUTPUT_DIR, \"images\")\n",
    "LABEL_DIR = IMAGE_DIR.replace(\"images\", \"labels\")\n",
    "\n",
    "# Create the directory structure\n",
    "for split in [\"train\", \"val\"]:\n",
    "    os.makedirs(os.path.join(IMAGE_DIR, split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(LABEL_DIR, split), exist_ok=True)\n",
    "\n",
    "# Load the dataset from the Hugging Face Hub\n",
    "dataset = load_dataset(REPO_ID)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T06:33:28.039238Z",
     "start_time": "2025-02-03T06:22:24.768193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_ultralytics_format(dataset_split, split):\n",
    "    \"\"\"\n",
    "    Save a dataset split into the Ultralytics format.\n",
    "    Args:\n",
    "        dataset_split: The dataset split (e.g., dataset[\"train\"])\n",
    "        split: \"train\" or \"val\"\n",
    "    \"\"\"\n",
    "    for example in dataset_split:\n",
    "        # Save the image to the appropriate folder\n",
    "        image = example[\"image\"]  # PIL.Image.Image\n",
    "        image_name = example[\"image_name\"]  # Original file name\n",
    "        output_image_path = os.path.join(IMAGE_DIR, split, image_name)\n",
    "\n",
    "        # Save the image object to disk\n",
    "        image.save(output_image_path)\n",
    "\n",
    "        # Save label\n",
    "        annotations = example[\"annotations\"]\n",
    "        label_name = image_name.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "        output_label_path = os.path.join(LABEL_DIR, split, label_name)\n",
    "        \n",
    "        with open(output_label_path, \"w\") as label_file:\n",
    "            label_file.write(annotations)\n",
    "\n",
    "# Save train and validation splits\n",
    "save_ultralytics_format(dataset[\"train\"], \"train\")\n",
    "save_ultralytics_format(dataset[\"val\"], \"val\")\n",
    "\n",
    "print(\"Dataset exported to Ultralytics format.\")"
   ],
   "id": "6301b5b2ff7fd878",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exported to Ultralytics format.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T07:02:43.833421Z",
     "start_time": "2025-02-03T07:02:42.993788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    " \n",
    "# Correctly set repo_id and repo_type\n",
    "repo_id = \"pyronear/pyro-sdis\"\n",
    "filename = \"data.yaml\"\n",
    "\n",
    "# Download data.yaml to the current directory\n",
    "yaml_path = hf_hub_download(repo_id=repo_id, filename=filename, repo_type=\"dataset\", local_dir=\".\")\n",
    "print(f\"data.yaml downloaded to: {yaml_path}\")"
   ],
   "id": "b9ce5e941b173604",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data.yaml:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "740b6e27368c47989a12b1905304ab3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml downloaded to: data.yaml\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# YOLO fine-tuning",
   "id": "e97076fde431ad02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "d722ade57b3b37c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T07:10:13.352674Z",
     "start_time": "2025-02-03T07:10:05.361688Z"
    }
   },
   "cell_type": "code",
   "source": "model = YOLO()",
   "id": "41d3a28fb1059f73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:05<00:00, 987kB/s] \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-03T07:13:49.525398Z"
    }
   },
   "cell_type": "code",
   "source": "results = model.train(data='data.yaml', epochs=25, batch=32, imgsz=720, dropout=0.5)",
   "id": "181475df30fb5a80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.70 ðŸš€ Python-3.10.12 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1050, 4034MiB)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=25, time=None, patience=100, batch=32, imgsz=720, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.5, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/theovld/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 2.32MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed âœ…\n",
      "WARNING âš ï¸ imgsz=[720] must be multiple of max stride 32, updating to [736]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /media/theovld/DATA1/ThÃ©o/DÃ©veloppement/Python/Frugal-AI/smoke-detection/datasets/pyro-sdis/labels/train... 11527 images, 2757 backgrounds, 8770 corrupt:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 11527/29537 [07:00<38:07,  7.87it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adding data augmentation",
   "id": "608a53dbfcb63fb5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
